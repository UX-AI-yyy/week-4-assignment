{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n7XGkmKXTat"
      },
      "outputs": [],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!wget -P ~ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i ~/cloudflared-linux-amd64.deb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSqhi6KzXvvr"
      },
      "outputs": [],
      "source": [
        "import os, subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_env = os.environ\n",
        "# my_env[\"OLLAMA_HOST\"] = \"0.0.0.0:11434\"\n",
        "# my_env[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "ollama_proc = subprocess.Popen(\"ollama serve\", env=my_env, shell=True)\n",
        "\n",
        "print(ollama_proc.pid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ollama pull llava\n",
        "!ollama pull llama3.2:1b\n",
        "!ollama pull deepseek-r1:14b\n",
        "!ollama list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tunnel_cmd = 'cloudflared tunnel --url http://localhost:11434 --http-host-header=\"localhost:11434\"'\n",
        "tunnel_proc = subprocess.Popen(tunnel_cmd, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "print(tunnel_proc.pid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(6):\n",
        "  print(tunnel_proc.stderr.readline())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e57vUjhCxfLh"
      },
      "outputs": [],
      "source": [
        "ollama_url = \"https://allergy-work-partners-section.trycloudflare.com\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMI8t_iqwkJ"
      },
      "source": [
        "### Prompt with Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests, base64\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from ollama import Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_data = requests.get(\"https://mystickermania.com/cdn/stickers/gudetama/gudetama-strawberry-512x512.png\").content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_data = Path(\"../imgs/GDTM.jpg\").read_bytes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = Client(host=ollama_url)\n",
        "\n",
        "img = base64.b64encode(img_data).decode()\n",
        "\n",
        "response = client.chat(\n",
        "    model='llava',\n",
        "    messages=[{\n",
        "        'role': 'user',\n",
        "        'content': 'What is in this image? Be concise.',\n",
        "        'images': [img],\n",
        "    }]\n",
        ")\n",
        "\n",
        "display(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwCkSI2jZ2yi"
      },
      "outputs": [],
      "source": [
        "client = Client(host=ollama_url)\n",
        "\n",
        "response = client.chat(\n",
        "    model='llama3.2:1b',\n",
        "    messages=[{\n",
        "        'role': 'user',\n",
        "        'content': 'Why are eggs yellow?',\n",
        "    }]\n",
        ")\n",
        "\n",
        "display(response)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
